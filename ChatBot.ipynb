{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import arxiv\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the OpenAI API client\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_recent_papers(topic, max_results=5):\n",
    "    try:\n",
    "        client = arxiv.Client()\n",
    "        search = arxiv.Search(\n",
    "            query=topic,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "        )\n",
    "        papers = []\n",
    "        for result in client.results(search):\n",
    "            papers.append({\n",
    "                'title': result.title,\n",
    "                'authors': [author.name for author in result.authors],\n",
    "                'summary': result.summary,\n",
    "                'url': result.pdf_url,\n",
    "                'published': result.published.strftime('%Y-%m-%d')\n",
    "            })\n",
    "        return papers\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching papers: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_paper(title, summary, url, published):\n",
    "    return f\"Title: {title}\\nPublished: {published}\\nURL: {url}\\nSummary: {summary}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt3_answer(question, context):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        answer = response['choices'][0]['message']['content'].strip()\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting GPT-3.5 Turbo answer: {e}\")\n",
    "        return \"An error occurred while fetching the answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_from_papers(papers):\n",
    "    context = \"\"\n",
    "    for paper in papers:\n",
    "        context += summarize_paper(paper['title'], paper['summary'], paper['url'], paper['published'])\n",
    "        context += \"\\n\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    topic = \"natural language processing\"\n",
    "    question = \"What are the latest advancements in natural language processing?\"\n",
    "\n",
    "    print(\"Fetching recent papers...\")\n",
    "    recent_papers = fetch_recent_papers(topic)\n",
    "    \n",
    "    if not recent_papers:\n",
    "        print(\"No recent papers found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Generating context from recent papers...\")\n",
    "    context = generate_context_from_papers(recent_papers)\n",
    "    \n",
    "    print(\"Getting answer from GPT-3.5 Turbo...\")\n",
    "    answer = get_gpt3_answer(question, context)\n",
    "    \n",
    "    print(\"\\nAnswer:\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching recent papers...\n",
      "Generating context from recent papers...\n",
      "Getting answer from GPT-3.5 Turbo...\n",
      "Error getting GPT-3.5 Turbo answer: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "\n",
      "Answer:\n",
      "An error occurred while fetching the answer.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
